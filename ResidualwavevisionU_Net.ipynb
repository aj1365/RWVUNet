{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMB19NeDZYwSgtAmEB0cw5w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aj1365/RWVUNet/blob/main/ResidualwavevisionU_Net.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h6VosyKJQwgw"
      },
      "outputs": [],
      "source": [
        "import h5py\n",
        "import cv2 # For CV operations\n",
        "from PIL import Image  #To create and store images\n",
        "import numpy as np\n",
        "import os\n",
        "from patchify import patchify\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "from typing import Callable"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images = []\n",
        "originalImages = os.listdir(\"E:/Flood mapping/VH/\")\n",
        "\n",
        "for index,image in enumerate(originalImages):\n",
        "    print(\"Image number : \" +str(index) )\n",
        "    img = Image.open(\"E:/Flood mapping/VH/\" + str(image))\n",
        "    img = img.resize((256, 256))\n",
        "    arr = np.array(img)\n",
        "    #arr = np.expand_dims(arr, -1)\n",
        "    images.append(arr)\n",
        "\n",
        "VH=images\n",
        "VH = np.array(VH)\n",
        "VH.shape\n",
        "\n",
        "\n",
        "images = []\n",
        "originalImages = os.listdir(\"E:/Flood mapping/labels/\")\n",
        "\n",
        "for index,image in enumerate(originalImages):\n",
        "    print(\"Image number : \" +str(index) )\n",
        "    img = Image.open(\"E:/Flood mapping/labels/\" + str(image))\n",
        "    img = img.resize((256, 256))\n",
        "    arr = np.array(img)\n",
        "    #arr = np.expand_dims(arr, -1)\n",
        "    images.append(arr)\n",
        "\n",
        "labels=images\n",
        "labels = np.array(labels)\n",
        "\n",
        "labels.shape\n",
        "\n",
        "\n",
        "images = []\n",
        "originalImages = os.listdir(\"E:/Flood mapping/VV/\")\n",
        "\n",
        "for index,image in enumerate(originalImages):\n",
        "    print(\"Image number : \" +str(index) )\n",
        "    img = Image.open(\"E:/Roy/Flood mapping/VV/\" + str(image))\n",
        "    img = img.resize((256, 256))\n",
        "    arr = np.array(img)\n",
        "    #arr = np.expand_dims(arr, -1)\n",
        "    images.append(arr)\n",
        "\n",
        "VV=images\n",
        "VV = np.array(VV)\n",
        "VV.shape\n",
        "\n",
        "VV=VV.reshape((VV.shape[0],VV.shape[1],VV.shape[2],1))\n",
        "VH=VH.reshape((VH.shape[0],VH.shape[1],VH.shape[2],1))\n",
        "\n",
        "\n",
        "S1=VV+VH\n",
        "S2=VH-VV\n",
        "S3=VV*VV\n",
        "S4=VH*VH\n",
        "S5=VV*VH\n",
        "S6=(VV+VH)*(VH-VV)\n",
        "\n",
        "meanVV = np.mean(VV)  # mean for data centering\n",
        "stdVV = np.std(VV)  # std for data normalization\n",
        "\n",
        "VV -= meanVV\n",
        "VV /= stdVV\n",
        "\n",
        "\n",
        "meanVH = np.mean(VH)  # mean for data centering\n",
        "stdVH = np.std(VH)  # std for data normalization\n",
        "\n",
        "VH -= meanVH\n",
        "VH /= stdVH\n",
        "\n",
        "meanS1 = np.mean(S1)  # mean for data centering\n",
        "stdS1 = np.std(S1)  # std for data normalization\n",
        "\n",
        "S1 -= meanS1\n",
        "S1 /= stdS1\n",
        "\n",
        "\n",
        "meanS2 = np.mean(S2)  # mean for data centering\n",
        "stdS2 = np.std(S2)  # std for data normalization\n",
        "\n",
        "S2 -= meanS2\n",
        "S2 /= stdS2\n",
        "\n",
        "\n",
        "meanS3 = np.mean(S3)  # mean for data centering\n",
        "stdS3 = np.std(S3)  # std for data normalization\n",
        "\n",
        "S3 -= meanS3\n",
        "S3 /= stdS3\n",
        "\n",
        "\n",
        "meanS4 = np.mean(S4)  # mean for data centering\n",
        "stdS4 = np.std(S4)  # std for data normalization\n",
        "\n",
        "S4 -= meanS4\n",
        "S4 /= stdS4\n",
        "\n",
        "\n",
        "meanS5 = np.mean(S5)  # mean for data centering\n",
        "stdS5 = np.std(S5)  # std for data normalization\n",
        "\n",
        "S5 -= meanS5\n",
        "S5 /= stdS5\n",
        "\n",
        "\n",
        "meanS6 = np.mean(S6)  # mean for data centering\n",
        "stdS6 = np.std(S6)  # std for data normalization\n",
        "\n",
        "S6 -= meanS6\n",
        "S6 /= stdS6\n",
        "\n",
        "SAR=np.concatenate((VV, VH, S1, S2, S3, S4, S5, S6) , axis = 3)\n"
      ],
      "metadata": {
        "id": "r19nk_pgQ9oy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SAR=np.concatenate((VV, VH, S1, S3, S4, S5, S6) , axis = 3)\n",
        "labels=labels.reshape((labels.shape[0],labels.shape[1],labels.shape[2],1))\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "TrainX, TestX, TrainY, TestY = train_test_split(SAR,\n",
        "                                                   labels,\n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state=0)"
      ],
      "metadata": {
        "id": "PnK6QH39RdTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with h5py.File(\"E:/Flood mapping/Data/Dataset_train.h5\", 'w') as hdf:\n",
        "    hdf.create_dataset('images', data=TrainX, compression='gzip', compression_opts=9)\n",
        "    hdf.create_dataset('masks', data=TrainY, compression='gzip', compression_opts=9)"
      ],
      "metadata": {
        "id": "0jSltu_PRj_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def DiceLoss(targets, inputs, smooth=1e-6):\n",
        "\n",
        "\n",
        "    intersection = K.sum(targets *inputs)\n",
        "    dice = (2*intersection + smooth) / (K.sum(targets) + K.sum(inputs) + smooth)\n",
        "    return 1 - dice\n",
        "\n",
        "def IoULoss(targets, inputs, smooth=1e-6):\n",
        "\n",
        "\n",
        "\n",
        "    intersection = K.sum(targets *inputs)\n",
        "    total = K.sum(targets) + K.sum(inputs)\n",
        "    union = total - intersection\n",
        "\n",
        "    IoU = (intersection + smooth) / (union + smooth)\n",
        "    return 1 - IoU"
      ],
      "metadata": {
        "id": "vdYIdMOcRkEs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Metrics to be used when evaluating the network\n",
        "\n",
        "from tensorflow_addons.metrics import F1Score\n",
        "\n",
        "precision = tf.keras.metrics.Precision()\n",
        "recall = tf.keras.metrics.Recall()\n",
        "f1 = F1Score(num_classes=2, name='f1', average='micro', threshold=0.4)\n",
        "sgd_optimizer = Adam()"
      ],
      "metadata": {
        "id": "xq2XJHONRkHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras_cv_attention_models import backend\n",
        "from keras_cv_attention_models.backend import layers, models, functional\n",
        "#from keras_cv_attention_models.models import register_model\n",
        "from keras_cv_attention_models.attention_layers import (\n",
        "    activation_by_name,\n",
        "    batchnorm_with_activation,\n",
        "    conv2d_no_bias,\n",
        "    drop_block,\n",
        "    group_norm,\n",
        "    # mlp_block, # cannot import name 'mlp_block' due to circular import\n",
        "    add_pre_post_process,\n",
        ")\n",
        "from keras_cv_attention_models.download_and_load import reload_model_weights\n"
      ],
      "metadata": {
        "id": "54z3Gy_MR0lU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mlp_block(inputs, hidden_dim, out_channel, drop_rate=0, activation=\"gelu\"):\n",
        "\n",
        "\n",
        "    nn = layers.Conv2D(hidden_dim, kernel_size=1, use_bias=True)(inputs)\n",
        "    nn = activation_by_name(nn, activation)\n",
        "    nn = layers.Dropout(drop_rate) if drop_rate > 0 else nn\n",
        "    nn = layers.Conv2D(out_channel, kernel_size=1, use_bias=True)(nn)\n",
        "    nn = layers.Dropout(drop_rate) if drop_rate > 0 else nn\n",
        "\n",
        "    return nn\n",
        "\n",
        "def phase_aware_token_mixing(inputs, out_channel=-1, qkv_bias=False, output_dropout=0, activation=\"gelu\"):\n",
        "\n",
        "    input_channel = inputs.shape[-1] if backend.image_data_format() == \"channels_last\" else inputs.shape[1]\n",
        "    out_channel = out_channel if out_channel > 0 else input_channel\n",
        "\n",
        "    theta_h = conv2d_no_bias(inputs, out_channel, kernel_size=1, use_bias=True)\n",
        "    theta_h = batchnorm_with_activation(theta_h, activation=\"relu\")  # Fixed as relu [ ??? ]\n",
        "    height = conv2d_no_bias(inputs, out_channel, kernel_size=1, use_bias=qkv_bias)\n",
        "    # height = layers.Concatenate(axis=-1)([height * functional.cos(theta_h), height * functional.sin(theta_h)])\n",
        "    height_cos = layers.Multiply()([height, functional.cos(theta_h)])\n",
        "    height_sin = layers.Multiply()([height, functional.sin(theta_h)])\n",
        "    height = layers.Concatenate(axis=-1 if backend.image_data_format() == \"channels_last\" else 1)([height_cos, height_sin])\n",
        "    height = conv2d_no_bias(height, out_channel, kernel_size=(1, 7), padding=\"same\", groups=out_channel, use_bias=False)\n",
        "\n",
        "    theta_w = conv2d_no_bias(inputs, out_channel, kernel_size=1, use_bias=True)\n",
        "    theta_w = batchnorm_with_activation(theta_w, activation=\"relu\")  # Fixed as relu [ ??? ]\n",
        "    width = conv2d_no_bias(inputs, out_channel, kernel_size=1, use_bias=qkv_bias)\n",
        "    # width = layers.Concatenate(axis=-1)([width * functional.cos(theta_w), width * functional.sin(theta_w)])\n",
        "    width_cos = layers.Multiply()([width, functional.cos(theta_w)])\n",
        "    width_sin = layers.Multiply()([width, functional.sin(theta_w)])\n",
        "    width = layers.Concatenate(axis=-1 if backend.image_data_format() == \"channels_last\" else 1)([width_cos, width_sin])\n",
        "    width = conv2d_no_bias(width, out_channel, kernel_size=(7, 1), padding=\"same\", groups=out_channel, use_bias=False)\n",
        "\n",
        "    channel = conv2d_no_bias(inputs, out_channel, kernel_size=1, use_bias=qkv_bias)\n",
        "\n",
        "    # print(f\"{height.shape = }, {width.shape = }, {channel.shape = }, {out_channel = }\")\n",
        "    nn = layers.Add()([height, width, channel])\n",
        "    nn = layers.GlobalAveragePooling2D(keepdims=True)(nn)\n",
        "    nn = mlp_block(nn, out_channel // 4, out_channel=out_channel * 3, activation=activation)\n",
        "    nn = layers.Reshape([1, 1, out_channel, 3] if backend.image_data_format() == \"channels_last\" else [out_channel, 1, 1, 3])(nn)\n",
        "    nn = layers.Softmax(axis=-1)(nn)\n",
        "    attn_height, attn_width, attn_channel = functional.unstack(nn, axis=-1)\n",
        "    # attn = layers.Add()([height * attn_height, width * attn_width, channel * attn_channel])\n",
        "    attn_height = layers.Multiply()([height, attn_height])\n",
        "    attn_width = layers.Multiply()([width, attn_width])\n",
        "    attn_channel = layers.Multiply()([channel, attn_channel])\n",
        "    # print(f\"{attn_height.shape = }, {attn_width.shape = }, {attn_channel.shape = }\")\n",
        "    attn = layers.Add()([attn_height, attn_width, attn_channel])\n",
        "\n",
        "    out = conv2d_no_bias(attn, out_channel, kernel_size=1, use_bias=True)\n",
        "    out = layers.Dropout(output_dropout)(out) if output_dropout > 0 else out\n",
        "\n",
        "    return out\n",
        "\n",
        "\n",
        "def wave_block(inputs, qkv_bias=False, mlp_ratio=4, use_group_norm=False, drop_rate=0, activation=\"gelu\"):\n",
        "\n",
        "    input_channel = inputs.shape[-1] if backend.image_data_format() == \"channels_last\" else inputs.shape[1]\n",
        "\n",
        "    attn = group_norm(inputs, groups=1) if use_group_norm else batchnorm_with_activation(inputs, activation=None)\n",
        "    attn = phase_aware_token_mixing(attn, out_channel=input_channel, qkv_bias=qkv_bias, activation=activation)\n",
        "    attn = drop_block(attn, drop_rate=drop_rate)\n",
        "    attn_out = layers.Add()([inputs, attn])\n",
        "\n",
        "    mlp = group_norm(attn_out, groups=1) if use_group_norm else batchnorm_with_activation(attn_out, activation=None)\n",
        "    mlp = mlp_block(mlp, int(input_channel * mlp_ratio), out_channel=input_channel, activation=activation)\n",
        "    mlp = drop_block(mlp)\n",
        "\n",
        "    mlp_out = layers.Add()([inputs, attn_out, mlp])\n",
        "\n",
        "    return mlp_out\n",
        "\n"
      ],
      "metadata": {
        "id": "GVQfItwzR0oo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "################################## LIBRARIES ##################################\n",
        "\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, Add, Conv2DTranspose, concatenate, Lambda, UpSampling2D\n",
        "from tensorflow.keras import Model, Input\n",
        "from contextlib import redirect_stdout\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "############################# CONVOLUTIONAL BLOCK #############################\n",
        "\n",
        "def conv_block(feature_map):\n",
        "\n",
        "    # Main Path\n",
        "    conv_1 = Conv2D(filters=64, kernel_size=(1,1), strides=(1,1), padding='same')(feature_map)\n",
        "    bn = BatchNormalization()(conv_1)\n",
        "    relu = Activation(activation='relu')(bn)\n",
        "    conv_2 = Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='same')(relu)\n",
        "\n",
        "    res_conn = Conv2D(filters=64, kernel_size=(5,5), strides=(1,1), padding='same')(feature_map)\n",
        "    res_conn = BatchNormalization()(res_conn)\n",
        "    addition = Add()([res_conn, conv_2])\n",
        "\n",
        "    return addition\n",
        "\n",
        "############################### RESIDUAL BLOCK ################################\n",
        "\n",
        "def res_block(feature_map, conv_filter, stride):\n",
        "\n",
        "    bn_1 = BatchNormalization()(feature_map)\n",
        "    relu_1 = Activation(activation='relu')(bn_1)\n",
        "    conv_1 = Conv2D(conv_filter, kernel_size=(3,3), strides=stride[0], padding='same')(relu_1)\n",
        "    bn_2 = BatchNormalization()(conv_1)\n",
        "    relu_2 = Activation(activation='relu')(bn_2)\n",
        "    conv_2 = Conv2D(conv_filter, kernel_size=(3,3), strides=stride[1], padding='same')(relu_2)\n",
        "\n",
        "\n",
        "    res_conn = Conv2D(conv_filter, kernel_size=(1,1), strides=stride[0], padding='same')(feature_map)\n",
        "    res_conn = BatchNormalization()(res_conn)\n",
        "    addition = Add()([res_conn, conv_2])\n",
        "\n",
        "    return addition\n",
        "\n",
        "################################### ENCODER ###################################\n",
        "\n",
        "def encoder(feature_map):\n",
        "\n",
        "    # Initialize the to_decoder connection\n",
        "    to_decoder = []\n",
        "\n",
        "    # Block 1 - Convolution Block\n",
        "    path = conv_block(feature_map)\n",
        "    to_decoder.append(path)\n",
        "\n",
        "    # Block 2 - Residual Block 1\n",
        "    path = res_block(path, 128, [(2, 2), (1, 1)])\n",
        "    to_decoder.append(path)\n",
        "\n",
        "    # Block 3 - Residual Block 2\n",
        "    path = res_block(path, 128, [(2, 2), (1, 1)])\n",
        "    to_decoder.append(path)\n",
        "\n",
        "    return to_decoder\n",
        "\n",
        "################################### DECODER ###################################\n",
        "\n",
        "def decoder(feature_map, from_encoder):\n",
        "\n",
        "    qkv_bias=False\n",
        "    mlp_ratio=2\n",
        "    use_group_norm=False\n",
        "    block_drop_rate=0\n",
        "\n",
        "\n",
        "    # Block 1: Up-sample, Concatenation + Residual Block 1\n",
        "    wave_block1 = wave_block(from_encoder[2], qkv_bias, mlp_ratio, use_group_norm, block_drop_rate, activation='ReLU')\n",
        "    main_path = UpSampling2D(size=(2,2), interpolation='bilinear')(feature_map)\n",
        "    # main_path = Conv2DTranspose(filters=256, kernel_size=(2,2), strides=(2,2), padding='same')(feature_map)\n",
        "    main_path = concatenate([main_path, wave_block1], axis=3)\n",
        "    main_path = res_block(main_path, 256, [(1, 1), (1, 1)])\n",
        "\n",
        "    # Block 2: Up-sample, Concatenation + Residual Block 2\n",
        "    wave_block2 = wave_block(from_encoder[1], qkv_bias, mlp_ratio, use_group_norm, block_drop_rate, activation='ReLU')\n",
        "    main_path = UpSampling2D(size=(2,2), interpolation='bilinear')(main_path)\n",
        "    # main_path = Conv2DTranspose(filters=128, kernel_size=(2,2), strides=(2,2), padding='same')(main_path)\n",
        "    main_path = concatenate([main_path, wave_block2], axis=3)\n",
        "    main_path = res_block(main_path, 128, [(1, 1), (1, 1)])\n",
        "\n",
        "    # Block 3: Up-sample, Concatenation + Residual Block 3\n",
        "    wave_block3 = wave_block(from_encoder[0], qkv_bias, mlp_ratio, use_group_norm, block_drop_rate, activation='ReLU')\n",
        "    main_path = UpSampling2D(size=(2,2), interpolation='bilinear')(main_path)\n",
        "    # main_path = Conv2DTranspose(filters=64, kernel_size=(2,2), strides=(2,2), padding='same')(main_path)\n",
        "    main_path = concatenate([main_path, wave_block3], axis=3)\n",
        "    main_path = res_block(main_path, 64, [(1, 1), (1, 1)])\n",
        "\n",
        "    return main_path\n",
        "\n",
        "################################ RESIDUAL UNET ################################\n",
        "\n",
        "def WaveResUNet():\n",
        "\n",
        "    num_blocks=[4]\n",
        "    out_channels=[128]\n",
        "    qkv_bias=False\n",
        "    mlp_ratios=[2]\n",
        "    use_group_norm=False\n",
        "    block_drop_rate=0\n",
        "    drop_connect_rate=0\n",
        "    use_downsample_norm=True\n",
        "\n",
        "    # Input\n",
        "    model_input = Input(shape=(256, 256, 7))\n",
        "\n",
        "    # Encoder Path\n",
        "    model_encoder = encoder(model_input)\n",
        "\n",
        "    # Bottleneck\n",
        "    X = res_block(model_encoder[2], 32, [(2, 2), (1, 1)])\n",
        "\n",
        "    total_blocks = sum(num_blocks)\n",
        "    global_block_id = 0\n",
        "\n",
        "    for stack_id, (num_block, out_channel, mlp_ratio) in enumerate(zip(num_blocks, out_channels, mlp_ratios)):\n",
        "        stage_name = \"stack{}_\".format(stack_id + 1)\n",
        "\n",
        "        if stack_id > 0:\n",
        "            X = conv2d_no_bias(X, out_channel, kernel_size=3, strides=2, padding=\"same\", use_bias=True)\n",
        "            if use_downsample_norm:\n",
        "\n",
        "                X = group_norm(X, groups=1) if use_group_norm else batchnorm_with_activation(X, activation=None)\n",
        "\n",
        "        for block_id in range(num_block):\n",
        "\n",
        "            block_drop_rate = drop_connect_rate * global_block_id / total_blocks\n",
        "            global_block_id += 1\n",
        "            X = wave_block(X, qkv_bias, mlp_ratio, use_group_norm, block_drop_rate, activation='ReLU')\n",
        "\n",
        "    # Decoder Path\n",
        "    model_decoder = decoder(X, model_encoder)\n",
        "\n",
        "    # Output\n",
        "    output_layer = Conv2D(filters=1, kernel_size=(1, 1), strides=(1, 1), activation='sigmoid', padding='same')(model_decoder)\n",
        "\n",
        "    model=Model(inputs=model_input, outputs=output_layer)\n",
        "    model.compile(optimizer=sgd_optimizer, loss='binary_crossentropy', metrics=['accuracy', precision, recall, f1])\n",
        "\n",
        "\n",
        "    return model\n",
        "\n",
        "model=WaveResUNet()"
      ],
      "metadata": {
        "id": "KDHhzbpER0rV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('*'*30)\n",
        "print('Loading and preprocessing train data...')\n",
        "print('*'*30)\n",
        "file = h5py.File('E:/Flood mapping/Data/Dataset_train.h5', 'r')\n",
        "imgs_train = file.get('images')\n",
        "imgs_mask_train = file.get('masks')\n",
        "imgs_train = np.array(imgs_train)\n",
        "imgs_mask_train = np.array(imgs_mask_train)\n",
        "\n",
        "print(imgs_train.shape)\n",
        "print(imgs_mask_train.shape)\n",
        "\n",
        "imgs_train = imgs_train.astype('float32')\n",
        "\n",
        "imgs_mask_train = imgs_mask_train.astype('float32')\n",
        "#imgs_mask_train /= 255  # scale masks to [0, 1]\n",
        "\n",
        "print('*'*30)\n",
        "print('Creating and compiling model...')\n",
        "print('*'*30)\n",
        "model=ResUNet()"
      ],
      "metadata": {
        "id": "7VVE06CZR0uD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weight_decay = 0.0001\n",
        "import tensorflow_addons as tfa\n",
        "learning_rate=1e-3\n",
        "optimizer = tfa.optimizers.AdamW(\n",
        "        learning_rate=learning_rate, weight_decay=weight_decay\n",
        "    )\n",
        "\n",
        "\n",
        "checkpoint_filepath = \"E:/Flood mapping/Data/wave_ResUNet.h5\"\n",
        "\n",
        "\n",
        "\n",
        "#with tf.device('/CPU:0'):\n",
        "history = model.fit(\n",
        "        x=imgs_train,\n",
        "        y=imgs_mask_train,\n",
        "        batch_size=1,\n",
        "        epochs=40,\n",
        "        validation_split=0.3\n",
        "    )\n"
      ],
      "metadata": {
        "id": "Sllb1OpWSSgt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testImages=TestX\n",
        "\n",
        "with h5py.File(\"E:/Flood mapping/Data/Dataset_test.h5\", 'w') as hdf:\n",
        "    hdf.create_dataset('images', data=testImages, compression='gzip', compression_opts=9)\n",
        "file = h5py.File('E:/Flood mapping/Data/Dataset_test.h5', 'r')\n",
        "imgs_test = file.get('images')\n",
        "#imgs_mask_test = file.get('masks')\n",
        "imgs_test = np.array(imgs_test)\n",
        "#imgs_mask_test = np.array(imgs_mask_test)\n",
        "imgs_test = imgs_test.astype('float32')\n",
        "#imgs_test -= mean\n",
        "#imgs_test /= std\n",
        "\n",
        "print('*'*30)\n",
        "print('Loading saved weights...')\n",
        "print('*'*30)\n",
        "model.load_weights('E:/Flood mapping/Data/wave_ResUNet.h5')\n",
        "\n",
        "print('*'*30)\n",
        "print('Predicting masks on test data...')\n",
        "print('*'*30)\n",
        "imgs_mask_test = model.predict(imgs_test, verbose=1,batch_size=1)\n",
        "imgs_mask_test=(imgs_mask_test - np.min(imgs_mask_test))/(np.max(imgs_mask_test) - np.min(imgs_mask_test))\n",
        "acc = model.evaluate(imgs_test, TestY, batch_size=1)"
      ],
      "metadata": {
        "id": "MbLVF71ZSSjs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}